{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(f\"PyTorch CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"PyTorch CUDA version: {torch.version.cuda}\")\n",
    "\n",
    "from torch import nn\n",
    "import torch.cuda.nvtx as nvtx\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "from torch.utils.cpp_extension import load_inline, load\n",
    "torch.utils.cpp_extension.CUDA_HOME = '/usr/local/cuda-13.0'\n",
    "print(f\"torch.utils.cpp_extension.CUDA_HOME reports: {torch.utils.cpp_extension.CUDA_HOME}\")\n",
    "\n",
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "torch.manual_seed(2244)\n",
    "\n",
    "# Define the CUDA kernel and C++ wrapper\n",
    "cuda_source = '''\n",
    "__global__ void square_matrix_kernel(const float* matrix, float* result, int width, int height) {\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    if (row < height && col < width) {\n",
    "        int idx = row * width + col;\n",
    "        result[idx] = matrix[idx] * matrix[idx];\n",
    "    }\n",
    "}\n",
    "\n",
    "torch::Tensor square_matrix(torch::Tensor matrix) {\n",
    "    const auto height = matrix.size(0);\n",
    "    const auto width = matrix.size(1);\n",
    "\n",
    "    auto result = torch::empty_like(matrix);\n",
    "\n",
    "    dim3 threads_per_block(16, 16);\n",
    "    dim3 number_of_blocks((width + threads_per_block.x - 1) / threads_per_block.x,\n",
    "                          (height + threads_per_block.y - 1) / threads_per_block.y);\n",
    "\n",
    "    square_matrix_kernel<<<number_of_blocks, threads_per_block>>>(\n",
    "        matrix.data_ptr<float>(), result.data_ptr<float>(), width, height);\n",
    "\n",
    "    return result;\n",
    "}\n",
    "'''\n",
    "\n",
    "cpp_source = \"torch::Tensor square_matrix(torch::Tensor matrix);\"\n",
    "\n",
    "# Load the CUDA kernel as a PyTorch extension\n",
    "square_matrix_extension = load_inline(\n",
    "    name='square_matrix_extension',\n",
    "    cpp_sources=cpp_source,\n",
    "    cuda_sources=cuda_source,\n",
    "    functions=['square_matrix'],\n",
    "    with_cuda=True,\n",
    "    extra_cuda_cflags=[\"-O3\"],\n",
    "    build_directory='./load_inline_cuda',\n",
    "    # extra_cuda_cflags=['--expt-relaxed-constexpr']\n",
    ")\n",
    "\n",
    "a = torch.tensor([[1., 2., 3.], [4., 5., 6.]], device='cuda')\n",
    "print(square_matrix_extension.square_matrix(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(1000, 1000, device='cuda')\n",
    "b = square_matrix_extension.square_matrix(a)\n",
    "a, b, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_source = '''\n",
    "#include <curand.h>\n",
    "\n",
    "#define gpuErrchk(ans) { gpuAssert((ans), __FILE__, __LINE__); }\n",
    "inline void gpuAssert(cudaError_t code, const char *file, int line, bool abort=true)\n",
    "{\n",
    "   if (code != cudaSuccess) \n",
    "   {\n",
    "      fprintf(stderr,\"GPUassert: %s %s %d\\\\n\", cudaGetErrorString(code), file, line);\n",
    "      if (abort) exit(code);\n",
    "   }\n",
    "}\n",
    "\n",
    "constexpr uint64_t multiplier = 6364136223846793005u;\n",
    "constexpr uint64_t increment  = 1442695040888963407u;\t// Or an arbitrary odd constant\n",
    "constexpr float pcg_norm = 1.f / 4294967296.f;\n",
    "constexpr int THREADS_PER_BLOCK = 128;\n",
    "\n",
    "__host__ __device__ uint32_t rotr32(uint32_t x, unsigned r) {\n",
    "\treturn x >> r | x << (-r & 31);\n",
    "}\n",
    "\n",
    "__host__ __device__ uint32_t pcg32(uint64_t& state) {\n",
    "\tuint64_t x = state;\n",
    "\tunsigned count = (unsigned)(x >> 59);\t\t// 59 = 64 - 5\n",
    "\n",
    "\tstate = x * multiplier + increment;\n",
    "\tx ^= x >> 18;\t\t\t\t\t\t\t\t// 18 = (64 - 27)/2\n",
    "\treturn rotr32((uint32_t)(x >> 27), count);\t// 27 = 32 - 5\n",
    "}\n",
    "\n",
    "__host__ __device__ void pcg32_init(uint64_t seed, uint64_t& state) {\n",
    "\tstate = seed + increment;\n",
    "\t(void)pcg32(state);\n",
    "}\n",
    "\n",
    "__host__ __device__ float randf_pcg32(float min_val, float max_val, uint64_t& state) {\n",
    "    uint32_t randint = pcg32(state);\n",
    "    float rand01 = randint * pcg_norm;\n",
    "    return min_val + rand01 * (max_val - min_val);\n",
    "}\n",
    "\n",
    "__global__ void init_pcg_states_kernel(uint64_t* pcg_states, int max_size) {\n",
    "\tint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    if (idx < max_size) {\n",
    "        pcg_states[idx] = 0x4d595df4d0f33173;\n",
    "        pcg32_init(idx, pcg_states[idx]);\n",
    "    }\n",
    "}\n",
    "\n",
    "uint64_t* d_pcg_states;\n",
    "void pcg_init(int max_size) {\n",
    "\tgpuErrchk(cudaMalloc(&d_pcg_states, max_size * sizeof(uint64_t)));\n",
    "\tint num_blocks = (max_size + THREADS_PER_BLOCK - 1) / THREADS_PER_BLOCK;\n",
    "\tinit_pcg_states_kernel<<<num_blocks, THREADS_PER_BLOCK>>>\n",
    " \t\t(d_pcg_states, max_size);\n",
    "}\n",
    "\n",
    "void pcg_destroy() {\n",
    "\tgpuErrchk(cudaFree(d_pcg_states));\n",
    "}\n",
    "\n",
    "\n",
    "/*\n",
    "        for id in range(self.NP):\n",
    "            nvtx.range_push(f\"updating model {id}\")\n",
    "            if fy[id] <= fx[id]:\n",
    "                for i in range(len(self.layers)):\n",
    "                    self.layers[i][id].copy_(y_layers[i][id])\n",
    "                    self.biases[i][id].copy_(y_biases[i][id])\n",
    "                fx[id] = fy[id]\n",
    "            if fx[id] < self.min_l:\n",
    "                self.best_model = id\n",
    "                self.min_l = fx[id]\n",
    "            nvtx.range_pop() */\n",
    "\n",
    "// MOVE d_y_params, d_mask INTO SHARED MEMORY, IDX >= NP SO JUST USE THE FIRST NP THREADS TO COOPERATIVELY LOAD\n",
    "__global__ void update_population_kernel(float* d_params, const float* d_y_params, const uint8_t* d_mask, int NP, int size) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    if (idx < NP * size) {\n",
    "        int id = idx / size;\n",
    "        \n",
    "        if (d_mask[id]) {\n",
    "            d_params[idx] = d_y_params[idx];\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "void de_update_cuda(int NP, std::vector<torch::Tensor>& layers, std::vector<torch::Tensor>& biases, const std::vector<torch::Tensor>& y_layers, const std::vector<torch::Tensor>& y_biases, torch::Tensor& fx, const torch::Tensor& fy, torch::Tensor& min_f, torch::Tensor& best_model) {\n",
    "    int num_layers = layers.size();\n",
    "    auto mask = torch::le(fy, fx).to(torch::kUInt8);\n",
    "    auto d_mask_ptr = mask.data_ptr<uint8_t>();\n",
    "    \n",
    "    for (int i = 0; i < num_layers; i++) {\n",
    "        torch::Tensor& layer = layers[i];\n",
    "        TORCH_CHECK(layer.is_contiguous(), \"'layers[\", i, \"]' must be contiguous\");\n",
    "\t\ttorch::Tensor& bias = biases[i];\n",
    "        TORCH_CHECK(bias.is_contiguous(), \"'biases[\", i, \"]' must be contiguous\");\n",
    "\n",
    "        torch::Tensor y_layer_contig = y_layers[i].contiguous();\n",
    "\t\ttorch::Tensor y_bias_contig = y_biases[i].contiguous();\n",
    "        update_population_kernel<<<(layer.numel() + THREADS_PER_BLOCK - 1) / THREADS_PER_BLOCK, THREADS_PER_BLOCK>>>\n",
    "        \t(layer.data_ptr<float>(), y_layer_contig.data_ptr<float>(), d_mask_ptr, NP, layer.numel() / NP);\n",
    "        update_population_kernel<<<(bias.numel() + THREADS_PER_BLOCK - 1) / THREADS_PER_BLOCK, THREADS_PER_BLOCK>>>\n",
    "        \t(bias.data_ptr<float>(), y_bias_contig.data_ptr<float>(), d_mask_ptr, NP, bias.numel() / NP);\n",
    "    }\n",
    "    \n",
    "    fx.copy_(torch::where(mask.to(torch::kBool), fy, fx));\n",
    "    \n",
    "    auto min_tuple = torch::min(fx, 0);\n",
    "    auto new_min_f = std::get<0>(min_tuple);\n",
    "    auto new_best_model = std::get<1>(min_tuple);\n",
    "    min_f.copy_(new_min_f);\n",
    "    best_model.copy_(new_best_model);\n",
    "    \n",
    "    cudaDeviceSynchronize();\n",
    "}\n",
    "\n",
    "\n",
    "// MOVE best_model (parameters), d_agent0_ids, d_agent1_ids, d_Rs, INTO SHARED MEMORY\n",
    "__global__ void de_crossover_kernel2(int NP, float CR, float F, int best_model, float* d_ptr, float* d_out_ptr, int size, int layer_idx, int num_layers, int* d_agent0_ids, int* d_agent1_ids, int* d_Rs, uint64_t* pcg_states) {\n",
    " \tint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "  \textern __shared__ float shared_buffer[];\n",
    "\tshared_buffer[threadIdx.x] = d_ptr[best_model * size + idx % size];\n",
    "\t\n",
    " \t__syncthreads();\n",
    "\tfloat* best_model_params = shared_buffer;\n",
    "\n",
    "\tif (idx < NP * size) {\n",
    "\t\tint id = idx / size; // candidate id\n",
    "\t\tfloat ri = randf_pcg32(0, 1, pcg_states[idx]);\n",
    "  \n",
    "\t\t// printf(\"id %d, agent_ids [%d, %d], R %d, (num_layers %d), ri %.3f\\\\n\", id, agent_ids[0], agent_ids[1], R, num_layers, ri);\n",
    "\n",
    "\t\tif (ri < CR || layer_idx == d_Rs[id]) {\n",
    "\t\t\td_out_ptr[idx] = d_ptr[idx] + F * (best_model_params[threadIdx.x] - d_ptr[idx]) +\n",
    "   \t\t\t\tF * (d_ptr[d_agent0_ids[id] * size + idx % size] - d_ptr[d_agent1_ids[id] * size + idx % size]);\n",
    "\t\t}\n",
    "\t}\n",
    "}\n",
    "\n",
    "// MOVE pcg_states INTO SHARED MEMORY\n",
    "__global__ void de_rng_kernel(int NP, int* d_agent0_ids, int* d_agent1_ids, int* d_Rs, int num_layers, uint64_t* pcg_states) {\n",
    "\tint id = blockIdx.x * blockDim.x + threadIdx.x;\n",
    " \n",
    "\tif (id < NP) {\n",
    "\t\td_Rs[id] = (int)randf_pcg32(0, num_layers, pcg_states[id]);\n",
    "\t\t\n",
    "  \t\tdo {\n",
    "\t\t\td_agent0_ids[id] = (int)randf_pcg32(0, NP, pcg_states[id]);\n",
    "\t\t} while (d_agent0_ids[id] == id);\n",
    "\n",
    "\t\tdo {\n",
    "\t\t\td_agent1_ids[id] = (int)randf_pcg32(0, NP, pcg_states[id]);\n",
    "\t\t} while (d_agent1_ids[id] == id || d_agent1_ids[id] == d_agent0_ids[id]);\n",
    "\t}\n",
    "}\n",
    "\n",
    "std::vector<std::vector<torch::Tensor>> de_crossover_cuda2(const std::vector<torch::Tensor>& layers, const std::vector<torch::Tensor>& biases, int64_t NP, double CR, double F, const torch::Tensor& best_model) {\n",
    "\tint num_layers = layers.size();\n",
    "\tstd::vector<float*> layer_ptrs(num_layers), bias_ptrs(num_layers);\n",
    " \tstd::vector<float*> out_layer_ptrs(num_layers), out_bias_ptrs(num_layers);\n",
    "\tstd::vector<torch::Tensor> out_layers(num_layers), out_biases(num_layers);\n",
    " \n",
    "\tint best_model_val = best_model.item<int>();\n",
    " \tint* d_agent0_ids;\n",
    "\tint* d_agent1_ids;\n",
    "\tint* d_Rs;\n",
    "\tgpuErrchk(cudaMalloc(&d_agent0_ids, NP * sizeof(int)));\n",
    " \tgpuErrchk(cudaMalloc(&d_agent1_ids, NP * sizeof(int)));\n",
    "\tgpuErrchk(cudaMalloc(&d_Rs, NP * sizeof(int)));\n",
    " \n",
    "\tde_rng_kernel<<<(NP + THREADS_PER_BLOCK - 1) / THREADS_PER_BLOCK, THREADS_PER_BLOCK>>>\n",
    " \t\t(NP, d_agent0_ids, d_agent1_ids, d_Rs, num_layers, d_pcg_states);\n",
    " \tgpuErrchk(cudaDeviceSynchronize());\n",
    "\n",
    "\tfor (int i = 0; i < num_layers; i++) {\n",
    "     \t//printf(\"layer %d:\\\\n\", i);\n",
    "\t\ttorch::Tensor layer_contig = layers[i].contiguous();\n",
    "\t\ttorch::Tensor bias_contig = biases[i].contiguous();\n",
    "\t\tlayer_ptrs[i] = layer_contig.data_ptr<float>();\n",
    "\t\tbias_ptrs[i] = bias_contig.data_ptr<float>();\n",
    "\n",
    "\t\tout_layers[i] = torch::clone(layer_contig);\n",
    "\t\tout_biases[i] = torch::clone(bias_contig);\n",
    "\t\tout_layer_ptrs[i] = out_layers[i].data_ptr<float>();\n",
    "\t\tout_bias_ptrs[i] = out_biases[i].data_ptr<float>();\n",
    "\t\t\n",
    "\t\tde_crossover_kernel2<<<max(1l, (layer_contig.numel() + THREADS_PER_BLOCK - 1) / THREADS_PER_BLOCK), THREADS_PER_BLOCK, THREADS_PER_BLOCK * sizeof(float)>>>\n",
    "  \t\t\t(NP, CR, F, best_model_val, layer_ptrs[i], out_layer_ptrs[i], layer_contig.numel() / NP, i, num_layers, d_agent0_ids, d_agent1_ids, d_Rs, d_pcg_states);\n",
    "\t\tde_crossover_kernel2<<<max(1l, (bias_contig.numel() + THREADS_PER_BLOCK - 1) / THREADS_PER_BLOCK), THREADS_PER_BLOCK, THREADS_PER_BLOCK * sizeof(float)>>>\n",
    "  \t\t\t(NP, CR, F, best_model_val, bias_ptrs[i], out_bias_ptrs[i], bias_contig.numel() / NP, i, num_layers, d_agent0_ids, d_agent1_ids, d_Rs, d_pcg_states);\n",
    "\t\t//gpuErrchk(cudaDeviceSynchronize());\n",
    "\t}\n",
    " \n",
    "   \tgpuErrchk(cudaDeviceSynchronize());\n",
    "    gpuErrchk(cudaFree(d_agent0_ids));\n",
    "    gpuErrchk(cudaFree(d_agent1_ids));\n",
    "\tgpuErrchk(cudaFree(d_Rs));\n",
    " \t//std::cout << \"crossover finished\" << std::endl;\n",
    " \treturn {out_layers, out_biases};\n",
    "}\n",
    "\n",
    "__global__ void de_crossover_kernel(int NP, float CR, float F, int best_model, float* d_ptr, float* d_out_ptr, int size, float* d_all_agent_ids, float* d_Rs, float* d_ris, int layer_idx, int num_layers) {\n",
    "\tint idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "\tif (idx < NP * size) {\n",
    "\t\tint id = idx / size; // candidate id\n",
    "\t\tint agent_ids[3]{d_all_agent_ids[id * 3 + 0] * NP, d_all_agent_ids[id * 3 + 1] * NP, d_all_agent_ids[id * 3 + 2] * NP};\n",
    "\t\t//printf(\"id: %d, best model: %d, agent 0: %d, agent 1: %d\\\\n\", id, best_model, agent_ids[0], agent_ids[1]);\n",
    "\t\tint R = d_Rs[id] * num_layers;\n",
    "\t\tfloat ri = d_ris[layer_idx * NP + id];\n",
    "  \n",
    "\t\t// printf(\"id %d, agent_ids [%d, %d, %d], R %d, (d_Rs %.3f, num_layers %d), ri %.3f\\\\n\", id, agent_ids[0], agent_ids[1], agent_ids[2], R, d_Rs[id], num_layers, ri);\n",
    "\n",
    "\t\tif (ri < CR || layer_idx == R) {\n",
    "\t\t\td_out_ptr[idx] = d_ptr[idx] + F * (d_ptr[best_model * size + idx % size] - d_ptr[idx]) + F * (d_ptr[agent_ids[0] * size + idx % size] - d_ptr[agent_ids[1] * size + idx % size]);\n",
    "\t\t\t//printf(\"crossover layer %d of id %d with agent0 %d and agent1 %d using ri %f and R %d \\\\n id d_ptr[%d] = %f best_model d_ptr[%d] = %f agent0 d_ptr[%d] = %f agent1 d_ptr[%d] = %f\\\\n\", layer_idx, id, agent_ids[0], agent_ids[1], ri, R,\n",
    "\t\t\t//\tidx, d_ptr[idx], best_model * size + idx % size, d_ptr[best_model * size + idx % size], agent_ids[0] * size + idx % size, d_ptr[agent_ids[0] * size + idx % size], agent_ids[1] * size + idx % size, d_ptr[agent_ids[1] * size + idx % size]);\n",
    "\t\t}\n",
    "\t}\n",
    "}\n",
    "\n",
    "curandGenerator_t gen;\n",
    "void curand_init() {\n",
    "\tcurandCreateGenerator(&gen, CURAND_RNG_PSEUDO_DEFAULT);\n",
    "\tcurandSetPseudoRandomGeneratorSeed(gen, 5691ULL);\n",
    "\tstd::cout << \"initializing curand\" << std::endl;\n",
    "}\n",
    "\n",
    "std::vector<std::vector<torch::Tensor>> de_crossover_cuda(const std::vector<torch::Tensor>& layers, const std::vector<torch::Tensor>& biases, int64_t NP, double CR, double F, int64_t best_model) {\n",
    "\tint num_layers = layers.size();\n",
    "\tstd::vector<float*> layer_ptrs(num_layers), bias_ptrs(num_layers);\n",
    " \tstd::vector<float*> out_layer_ptrs(num_layers), out_bias_ptrs(num_layers);\n",
    "\tstd::vector<torch::Tensor> out_layers(num_layers), out_biases(num_layers);\n",
    "\n",
    "\tfloat* d_all_agent_ids;\n",
    "\tfloat* d_Rs;\n",
    "\tfloat* d_ris;\n",
    "\tint num_agents = NP * 3, num_Rs = NP, num_ris = num_layers * NP;\n",
    "\tgpuErrchk(cudaMalloc(&d_all_agent_ids, num_agents * sizeof(float)));\n",
    "\tgpuErrchk(cudaMalloc(&d_Rs, num_Rs * sizeof(float)));\n",
    "\tgpuErrchk(cudaMalloc(&d_ris, num_ris * sizeof(float)));\n",
    "\n",
    "\tcurandGenerateUniform(gen, d_all_agent_ids, num_agents);\n",
    "\tcurandGenerateUniform(gen, d_Rs, num_Rs);\n",
    "\tcurandGenerateUniform(gen, d_ris, num_ris);\n",
    "\t//std::cout << \"num_layers \" << num_layers << std::endl;\n",
    "\n",
    "\tfor (int i = 0; i < num_layers; i++) {\n",
    "     \t//printf(\"layer %d:\\\\n\", i);\n",
    "\t\t\n",
    "\t\ttorch::Tensor layer_contig = layers[i].contiguous();\n",
    "\t\ttorch::Tensor bias_contig = biases[i].contiguous();\n",
    "\t\tlayer_ptrs[i] = layer_contig.data_ptr<float>();\n",
    "\t\tbias_ptrs[i] = bias_contig.data_ptr<float>();\n",
    "\n",
    "\t\t//out_layers[i] = torch::empty(layer_contig.sizes(), layer_contig.options());\n",
    "\t\t//out_biases[i] = torch::empty(bias_contig.sizes(), bias_contig.options());\n",
    "\t\tout_layers[i] = torch::clone(layer_contig);\n",
    "\t\tout_biases[i] = torch::clone(bias_contig);\n",
    "\t\tout_layer_ptrs[i] = out_layers[i].data_ptr<float>();\n",
    "\t\tout_bias_ptrs[i] = out_biases[i].data_ptr<float>();\n",
    "\n",
    "\t\tde_crossover_kernel<<<max(1l, (layer_contig.numel() + THREADS_PER_BLOCK - 1) / THREADS_PER_BLOCK), THREADS_PER_BLOCK>>>(NP, CR, F, best_model, layer_ptrs[i], out_layer_ptrs[i], layer_contig.numel() / NP, d_all_agent_ids, d_Rs, d_ris, i, num_layers);\n",
    "\t\tde_crossover_kernel<<<max(1l, (bias_contig.numel() + THREADS_PER_BLOCK - 1) / THREADS_PER_BLOCK), THREADS_PER_BLOCK>>>(NP, CR, F, best_model, bias_ptrs[i], out_bias_ptrs[i], bias_contig.numel() / NP, d_all_agent_ids, d_Rs, d_ris, i, num_layers);\n",
    "\t\t\n",
    "\t\tgpuErrchk(cudaDeviceSynchronize());\n",
    "\t\t//std::cout << \"layer \" << i << \" has \" << layer_contig.numel() / NP << \" parameters\" << std::endl;\n",
    "\t\t//std::cout << \"bias  \" << i << \" has \" << bias_contig.numel() / NP  << \" parameters\" << std::endl;\n",
    "\t}\n",
    " \n",
    "   \tgpuErrchk(cudaDeviceSynchronize());\n",
    "\tgpuErrchk(cudaFree(d_all_agent_ids));\n",
    "\tgpuErrchk(cudaFree(d_Rs));\n",
    "\tgpuErrchk(cudaFree(d_ris));\n",
    " \t//std::cout << \"crossover finished\" << std::endl;\n",
    " \treturn {out_layers, out_biases};\n",
    "}\n",
    "'''\n",
    "\n",
    "cpp_source = '''\n",
    "void pcg_init(int max_size);\n",
    "void pcg_destroy();\n",
    "void curand_init();\n",
    "std::vector<std::vector<torch::Tensor>> de_crossover_cuda(const std::vector<torch::Tensor>& layers, const std::vector<torch::Tensor>& biases, int64_t NP, double CR, double F, int64_t best_model);\n",
    "std::vector<std::vector<torch::Tensor>> de_crossover_cuda2(const std::vector<torch::Tensor>& layers, const std::vector<torch::Tensor>& biases, int64_t NP, double CR, double F, const torch::Tensor& best_model);\n",
    "void de_update_cuda(int NP, std::vector<torch::Tensor>& layers, std::vector<torch::Tensor>& biases, const std::vector<torch::Tensor>& y_layers, const std::vector<torch::Tensor>& y_biases, torch::Tensor& fx, const torch::Tensor& fy, torch::Tensor& min_f, torch::Tensor& best_model);\n",
    "'''\n",
    "\n",
    "# Load the CUDA kernel as a PyTorch extension\n",
    "diff_evo = load_inline(\n",
    "    name='diff_evo',\n",
    "    cpp_sources=cpp_source,\n",
    "    cuda_sources=cuda_source,\n",
    "    functions=['de_crossover_cuda', 'de_crossover_cuda2', 'de_update_cuda', 'curand_init', 'pcg_init', 'pcg_destroy'],\n",
    "    with_cuda=True,\n",
    "    extra_cuda_cflags=[\"-O3\", \"-lcurand\"],\n",
    "    build_directory='./diff_evo_cuda',\n",
    "    # extra_cuda_cflags=['--expt-relaxed-constexpr']\n",
    ")\n",
    "\n",
    "diff_evo.curand_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NP = 5\n",
    "lin1s = nn.init.kaiming_uniform_(torch.empty((NP, 1, 1), requires_grad=False).to(device, non_blocking=True))\n",
    "lin2s = nn.init.kaiming_uniform_(torch.empty((NP, 2, 2), requires_grad=False).to(device, non_blocking=True))\n",
    "layers = [lin1s, lin2s]\n",
    "#print(layers)\n",
    "\n",
    "bias1 = nn.init.kaiming_uniform_(torch.empty((NP, 1, 1), requires_grad=False).to(device, non_blocking=True))\n",
    "bias2 = nn.init.kaiming_uniform_(torch.empty((NP, 2, 1), requires_grad=False).to(device, non_blocking=True))\n",
    "biases = [bias1, bias2]\n",
    "\n",
    "diff_evo.pcg_init(200)\n",
    "lst = diff_evo.de_crossover_cuda2(layers, biases, NP, 0.9, 0.8, torch.tensor(0).to(device))\n",
    "print(lst[0])\n",
    "diff_evo.pcg_destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NP = 44\n",
    "lin1s = nn.init.kaiming_uniform_(torch.empty((NP, 4, 1), requires_grad=False).to(device, non_blocking=True))\n",
    "lin2s = nn.init.kaiming_uniform_(torch.empty((NP, 8, 4), requires_grad=False).to(device, non_blocking=True))\n",
    "lin3s = nn.init.kaiming_uniform_(torch.empty((NP, 4, 8), requires_grad=False).to(device, non_blocking=True))\n",
    "lin4s = nn.init.kaiming_uniform_(torch.empty((NP, 1, 4), requires_grad=False).to(device, non_blocking=True))\n",
    "layers = [lin1s, lin2s, lin3s, lin4s]\n",
    "\n",
    "bias1 = nn.init.kaiming_uniform_(torch.empty((NP, 4, 1), requires_grad=False).to(device, non_blocking=True))\n",
    "bias2 = nn.init.kaiming_uniform_(torch.empty((NP, 8, 1), requires_grad=False).to(device, non_blocking=True))\n",
    "bias3 = nn.init.kaiming_uniform_(torch.empty((NP, 4, 1), requires_grad=False).to(device, non_blocking=True))\n",
    "bias4 = nn.init.kaiming_uniform_(torch.empty((NP, 1, 1), requires_grad=False).to(device, non_blocking=True))\n",
    "biases = [bias1, bias2, bias3, bias4]\n",
    "\n",
    "diff_evo.de_crossover_cuda(layers, biases, NP, 0.9, 0.8, torch.tensor(0).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, mu):\n",
    "    return (1 / (0.3 * math.sqrt(2 * math.pi))) * (math.e ** ((-1/2) * (((x - mu) / 0.3)) ** 2))\n",
    "\n",
    "def gaussian_mixture(x, theta):\n",
    "    return gaussian(x, theta[0]) + gaussian(x, theta[1]) + gaussian(x, theta[2]) + gaussian(x, theta[3])\n",
    "\n",
    "class DE_NN(nn.Module):\n",
    "    def __init__(self, NP, CR, F):\n",
    "        super(DE_NN, self).__init__()\n",
    "        lin1s = nn.init.kaiming_uniform_(torch.empty((NP, 4, 1), requires_grad=False).to(device, non_blocking=True))\n",
    "        lin2s = nn.init.kaiming_uniform_(torch.empty((NP, 8, 4), requires_grad=False).to(device, non_blocking=True))\n",
    "        lin3s = nn.init.kaiming_uniform_(torch.empty((NP, 4, 8), requires_grad=False).to(device, non_blocking=True))\n",
    "        lin4s = nn.init.kaiming_uniform_(torch.empty((NP, 1, 4), requires_grad=False).to(device, non_blocking=True))\n",
    "        self.layers = [lin1s, lin2s, lin3s, lin4s]\n",
    "        bias1 = nn.init.kaiming_uniform_(torch.empty((NP, 4, 1), requires_grad=False).to(device, non_blocking=True))\n",
    "        bias2 = nn.init.kaiming_uniform_(torch.empty((NP, 8, 1), requires_grad=False).to(device, non_blocking=True))\n",
    "        bias3 = nn.init.kaiming_uniform_(torch.empty((NP, 4, 1), requires_grad=False).to(device, non_blocking=True))\n",
    "        bias4 = nn.init.kaiming_uniform_(torch.empty((NP, 1, 1), requires_grad=False).to(device, non_blocking=True))\n",
    "        self.biases = [bias1, bias2, bias3, bias4]\n",
    "        \n",
    "        max_size = 0\n",
    "        for layer in self.layers:\n",
    "            max_size = max(max_size, layer.numel())\n",
    "        for bias in self.biases:\n",
    "            max_size = max(max_size, bias.numel())\n",
    "        diff_evo.pcg_init(max_size)\n",
    "        self.max_size = max_size\n",
    "        \n",
    "        self.NP = NP\n",
    "        self.CR = CR\n",
    "        self.F = F\n",
    "        self.min_f = torch.tensor(float('inf')).to(device)\n",
    "        self.best_model = torch.tensor(0).to(device)\n",
    "        self.fx = None\n",
    "    def forward_all(self, X, layers, biases):\n",
    "        # This is just bmm???\n",
    "        for i in range(len(layers) - 1):\n",
    "            X = torch.relu(torch.einsum('lik,lkj->lij', layers[i], X) + biases[i])\n",
    "        X = torch.einsum('lik,lkj->lij', layers[len(layers) - 1], X) + biases[len(layers) - 1]\n",
    "        return X\n",
    "    def forward(self, X):\n",
    "        for i in range(len(self.layers) - 1):\n",
    "            X = torch.relu(torch.matmul(self.layers[i][self.best_model], X) + self.biases[i][self.best_model])\n",
    "        return torch.matmul(self.layers[len(self.layers) - 1][self.best_model], X) + self.biases[len(self.layers) - 1][self.best_model]\n",
    "    def step(self, X, Y, L, type='param'): # forward pass with candidate i\n",
    "        if self.fx == None:\n",
    "            self.fx = L(self.forward_all(X, self.layers, self.biases), Y).mean(dim = 2).squeeze(-1)\n",
    "        \n",
    "        #y_layers, y_biases = diff_evo.de_crossover_cuda(self.layers, self.biases, self.NP, self.CR, self.F, self.best_model)\n",
    "        y_layers, y_biases = diff_evo.de_crossover_cuda2(self.layers, self.biases, self.NP, self.CR, self.F, self.best_model)\n",
    "        fy = L(self.forward_all(X, y_layers, y_biases), Y).mean(dim = 2).squeeze(-1)\n",
    "        diff_evo.de_update_cuda(self.NP, self.layers, self.biases, y_layers, y_biases, self.fx, fy, self.min_f, self.best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5000\n",
    "batch_size = 10000\n",
    "my_theta = [0.1, 1, 1.8, 2]\n",
    "\n",
    "NP = 44\n",
    "CR = 0.9\n",
    "F = 0.8\n",
    "X = torch.rand(1, batch_size).to(device) * 5 - 1\n",
    "Y = gaussian_mixture(X, my_theta).to(device)\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "X = X.unsqueeze(0).expand(NP, 1, batch_size)\n",
    "Y = Y.unsqueeze(0).expand(NP, 1, batch_size)\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "model = DE_NN(NP, CR, F).to(device) \n",
    "model = torch.compile(model, mode=\"max-autotune\")\n",
    "print('pcg with max size', model.max_size)\n",
    "L = nn.MSELoss(reduction='none')\n",
    "\n",
    "Y_pred = model.forward_all(X, model.layers, model.biases)\n",
    "print(Y_pred.shape)\n",
    "\n",
    "for e in range(epochs):\n",
    "    model.step(X, Y, L, 'block')\n",
    "    if e % 100 == 0 or e == epochs - 1:\n",
    "        with torch.no_grad():\n",
    "            test_X = torch.linspace(-1, 3, 1000).unsqueeze(0)\n",
    "            test_Y = gaussian_mixture(test_X, my_theta)\n",
    "            model_Y = model(test_X.to(device)).cpu()\n",
    "            # Clear the previous output before plotting\n",
    "            clear_output(wait=True)\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(test_X.numpy()[0], test_Y.numpy()[0], label='Gaussian Mixture')\n",
    "            plt.plot(test_X.numpy()[0], model_Y.numpy()[0], label='Predictions', color='red', linestyle='dotted')\n",
    "            plt.title(f'Gaussian Mixture Plot {model.min_f.item()} epoch {e}')\n",
    "            plt.xlabel('X')\n",
    "            plt.ylabel('Y')\n",
    "            plt.grid(True)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[84]\u001b[39m\u001b[32m, line 113\u001b[39m\n\u001b[32m    111\u001b[39m     ax.grid(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    112\u001b[39m axes[\u001b[32m0\u001b[39m].set_ylabel(\u001b[33m'\u001b[39m\u001b[33mY\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m \u001b[43mplt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/programming-projects/realtime-nn/.venv/lib/python3.12/site-packages/matplotlib/pyplot.py:613\u001b[39m, in \u001b[36mshow\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    569\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    570\u001b[39m \u001b[33;03mDisplay all open figures.\u001b[39;00m\n\u001b[32m    571\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    610\u001b[39m \u001b[33;03mexplicitly there.\u001b[39;00m\n\u001b[32m    611\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    612\u001b[39m _warn_if_gui_out_of_main_thread()\n\u001b[32m--> \u001b[39m\u001b[32m613\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_backend_mod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/programming-projects/realtime-nn/.venv/lib/python3.12/site-packages/matplotlib_inline/backend_inline.py:90\u001b[39m, in \u001b[36mshow\u001b[39m\u001b[34m(close, block)\u001b[39m\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m figure_manager \u001b[38;5;129;01min\u001b[39;00m Gcf.get_all_fig_managers():\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m         \u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfigure_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcanvas\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfigure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_fetch_figure_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfigure_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcanvas\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfigure\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     95\u001b[39m     show._to_draw = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/programming-projects/realtime-nn/.venv/lib/python3.12/site-packages/IPython/core/display_functions.py:278\u001b[39m, in \u001b[36mdisplay\u001b[39m\u001b[34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[39m\n\u001b[32m    276\u001b[39m     publish_display_data(data=obj, metadata=metadata, **kwargs)\n\u001b[32m    277\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m278\u001b[39m     format_dict, md_dict = \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    279\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m format_dict:\n\u001b[32m    280\u001b[39m         \u001b[38;5;66;03m# nothing to display (e.g. _ipython_display_ took over)\u001b[39;00m\n\u001b[32m    281\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/programming-projects/realtime-nn/.venv/lib/python3.12/site-packages/IPython/core/formatters.py:238\u001b[39m, in \u001b[36mDisplayFormatter.format\u001b[39m\u001b[34m(self, obj, include, exclude)\u001b[39m\n\u001b[32m    236\u001b[39m md = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m238\u001b[39m     data = \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# FIXME: log the exception\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/programming-projects/realtime-nn/.venv/lib/python3.12/site-packages/decorator.py:235\u001b[39m, in \u001b[36mdecorate.<locals>.fun\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[32m    234\u001b[39m     args, kw = fix(args, kw, sig)\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcaller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/programming-projects/realtime-nn/.venv/lib/python3.12/site-packages/IPython/core/formatters.py:282\u001b[39m, in \u001b[36mcatch_format_error\u001b[39m\u001b[34m(method, self, *args, **kwargs)\u001b[39m\n\u001b[32m    280\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"show traceback on failed format call\"\"\"\u001b[39;00m\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m     r = \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[32m    284\u001b[39m     \u001b[38;5;66;03m# don't warn on NotImplementedErrors\u001b[39;00m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._check_return(\u001b[38;5;28;01mNone\u001b[39;00m, args[\u001b[32m0\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/programming-projects/realtime-nn/.venv/lib/python3.12/site-packages/IPython/core/formatters.py:402\u001b[39m, in \u001b[36mBaseFormatter.__call__\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprinter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[38;5;66;03m# Finally look for special method names\u001b[39;00m\n\u001b[32m    404\u001b[39m method = get_real_method(obj, \u001b[38;5;28mself\u001b[39m.print_method)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/programming-projects/realtime-nn/.venv/lib/python3.12/site-packages/IPython/core/pylabtools.py:170\u001b[39m, in \u001b[36mprint_figure\u001b[39m\u001b[34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[39m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend_bases\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FigureCanvasBase\n\u001b[32m    168\u001b[39m     FigureCanvasBase(fig)\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m \u001b[43mfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcanvas\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbytes_io\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    171\u001b[39m data = bytes_io.getvalue()\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fmt == \u001b[33m'\u001b[39m\u001b[33msvg\u001b[39m\u001b[33m'\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/programming-projects/realtime-nn/.venv/lib/python3.12/site-packages/matplotlib/backend_bases.py:2157\u001b[39m, in \u001b[36mFigureCanvasBase.print_figure\u001b[39m\u001b[34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[39m\n\u001b[32m   2154\u001b[39m     \u001b[38;5;66;03m# we do this instead of `self.figure.draw_without_rendering`\u001b[39;00m\n\u001b[32m   2155\u001b[39m     \u001b[38;5;66;03m# so that we can inject the orientation\u001b[39;00m\n\u001b[32m   2156\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(renderer, \u001b[33m\"\u001b[39m\u001b[33m_draw_disabled\u001b[39m\u001b[33m\"\u001b[39m, nullcontext)():\n\u001b[32m-> \u001b[39m\u001b[32m2157\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfigure\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2158\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m bbox_inches:\n\u001b[32m   2159\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches == \u001b[33m\"\u001b[39m\u001b[33mtight\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/programming-projects/realtime-nn/.venv/lib/python3.12/site-packages/matplotlib/artist.py:94\u001b[39m, in \u001b[36m_finalize_rasterization.<locals>.draw_wrapper\u001b[39m\u001b[34m(artist, renderer, *args, **kwargs)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(draw)\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdraw_wrapper\u001b[39m(artist, renderer, *args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m     result = \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m renderer._rasterizing:\n\u001b[32m     96\u001b[39m         renderer.stop_rasterizing()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/programming-projects/realtime-nn/.venv/lib/python3.12/site-packages/matplotlib/artist.py:71\u001b[39m, in \u001b[36mallow_rasterization.<locals>.draw_wrapper\u001b[39m\u001b[34m(artist, renderer)\u001b[39m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     69\u001b[39m         renderer.start_filter()\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/programming-projects/realtime-nn/.venv/lib/python3.12/site-packages/matplotlib/figure.py:3257\u001b[39m, in \u001b[36mFigure.draw\u001b[39m\u001b[34m(self, renderer)\u001b[39m\n\u001b[32m   3254\u001b[39m             \u001b[38;5;66;03m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[32m   3256\u001b[39m     \u001b[38;5;28mself\u001b[39m.patch.draw(renderer)\n\u001b[32m-> \u001b[39m\u001b[32m3257\u001b[39m     \u001b[43mmimage\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3260\u001b[39m     renderer.close_group(\u001b[33m'\u001b[39m\u001b[33mfigure\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m   3261\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/programming-projects/realtime-nn/.venv/lib/python3.12/site-packages/matplotlib/image.py:134\u001b[39m, in \u001b[36m_draw_list_compositing_images\u001b[39m\u001b[34m(renderer, parent, artists, suppress_composite)\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[32m    133\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m         \u001b[43ma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    136\u001b[39m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[32m    137\u001b[39m     image_group = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/programming-projects/realtime-nn/.venv/lib/python3.12/site-packages/matplotlib/artist.py:71\u001b[39m, in \u001b[36mallow_rasterization.<locals>.draw_wrapper\u001b[39m\u001b[34m(artist, renderer)\u001b[39m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     69\u001b[39m         renderer.start_filter()\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/programming-projects/realtime-nn/.venv/lib/python3.12/site-packages/matplotlib/axes/_base.py:3226\u001b[39m, in \u001b[36m_AxesBase.draw\u001b[39m\u001b[34m(self, renderer)\u001b[39m\n\u001b[32m   3223\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m artists_rasterized:\n\u001b[32m   3224\u001b[39m     _draw_rasterized(\u001b[38;5;28mself\u001b[39m.get_figure(root=\u001b[38;5;28;01mTrue\u001b[39;00m), artists_rasterized, renderer)\n\u001b[32m-> \u001b[39m\u001b[32m3226\u001b[39m \u001b[43mmimage\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3227\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3229\u001b[39m renderer.close_group(\u001b[33m'\u001b[39m\u001b[33maxes\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m   3230\u001b[39m \u001b[38;5;28mself\u001b[39m.stale = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/programming-projects/realtime-nn/.venv/lib/python3.12/site-packages/matplotlib/image.py:134\u001b[39m, in \u001b[36m_draw_list_compositing_images\u001b[39m\u001b[34m(renderer, parent, artists, suppress_composite)\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[32m    133\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m         \u001b[43ma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    136\u001b[39m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[32m    137\u001b[39m     image_group = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/programming-projects/realtime-nn/.venv/lib/python3.12/site-packages/matplotlib/artist.py:71\u001b[39m, in \u001b[36mallow_rasterization.<locals>.draw_wrapper\u001b[39m\u001b[34m(artist, renderer)\u001b[39m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     69\u001b[39m         renderer.start_filter()\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/programming-projects/realtime-nn/.venv/lib/python3.12/site-packages/matplotlib/axis.py:1411\u001b[39m, in \u001b[36mAxis.draw\u001b[39m\u001b[34m(self, renderer)\u001b[39m\n\u001b[32m   1408\u001b[39m     tick.draw(renderer)\n\u001b[32m   1410\u001b[39m \u001b[38;5;66;03m# Shift label away from axes to avoid overlapping ticklabels.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1411\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_label_position\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1412\u001b[39m \u001b[38;5;28mself\u001b[39m.label.draw(renderer)\n\u001b[32m   1414\u001b[39m \u001b[38;5;28mself\u001b[39m._update_offset_text_position(tlb1, tlb2)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/programming-projects/realtime-nn/.venv/lib/python3.12/site-packages/matplotlib/axis.py:2681\u001b[39m, in \u001b[36mYAxis._update_label_position\u001b[39m\u001b[34m(self, renderer)\u001b[39m\n\u001b[32m   2676\u001b[39m x, y = \u001b[38;5;28mself\u001b[39m.label.get_position()\n\u001b[32m   2678\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.label_position == \u001b[33m'\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m   2679\u001b[39m     \u001b[38;5;66;03m# Union with extents of the left spine if present, of the axes otherwise.\u001b[39;00m\n\u001b[32m   2680\u001b[39m     bbox = mtransforms.Bbox.union([\n\u001b[32m-> \u001b[39m\u001b[32m2681\u001b[39m         *bboxes, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maxes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mspines\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mleft\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maxes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_window_extent\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m])\n\u001b[32m   2682\u001b[39m     \u001b[38;5;28mself\u001b[39m.label.set_position(\n\u001b[32m   2683\u001b[39m         (bbox.x0 - \u001b[38;5;28mself\u001b[39m.labelpad * \u001b[38;5;28mself\u001b[39m.get_figure(root=\u001b[38;5;28;01mTrue\u001b[39;00m).dpi / \u001b[32m72\u001b[39m, y))\n\u001b[32m   2684\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2685\u001b[39m     \u001b[38;5;66;03m# Union with extents of the right spine if present, of the axes otherwise.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/programming-projects/realtime-nn/.venv/lib/python3.12/site-packages/matplotlib/spines.py:158\u001b[39m, in \u001b[36mSpine.get_window_extent\u001b[39m\u001b[34m(self, renderer)\u001b[39m\n\u001b[32m    156\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m bb\n\u001b[32m    157\u001b[39m bboxes = [bb]\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m drawn_ticks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_update_ticks\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    160\u001b[39m major_tick = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m({*drawn_ticks} & {*\u001b[38;5;28mself\u001b[39m.axis.majorTicks}), \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    161\u001b[39m minor_tick = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m({*drawn_ticks} & {*\u001b[38;5;28mself\u001b[39m.axis.minorTicks}), \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/programming-projects/realtime-nn/.venv/lib/python3.12/site-packages/matplotlib/axis.py:1288\u001b[39m, in \u001b[36mAxis._update_ticks\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1286\u001b[39m     tick.label1.set_text(label)\n\u001b[32m   1287\u001b[39m     tick.label2.set_text(label)\n\u001b[32m-> \u001b[39m\u001b[32m1288\u001b[39m minor_locs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_minorticklocs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1289\u001b[39m minor_labels = \u001b[38;5;28mself\u001b[39m.minor.formatter.format_ticks(minor_locs)\n\u001b[32m   1290\u001b[39m minor_ticks = \u001b[38;5;28mself\u001b[39m.get_minor_ticks(\u001b[38;5;28mlen\u001b[39m(minor_locs))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/programming-projects/realtime-nn/.venv/lib/python3.12/site-packages/matplotlib/axis.py:1532\u001b[39m, in \u001b[36mAxis.get_minorticklocs\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1530\u001b[39m minor_locs = np.asarray(\u001b[38;5;28mself\u001b[39m.minor.locator())\n\u001b[32m   1531\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.remove_overlapping_locs:\n\u001b[32m-> \u001b[39m\u001b[32m1532\u001b[39m     major_locs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmajor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlocator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1533\u001b[39m     transform = \u001b[38;5;28mself\u001b[39m._scale.get_transform()\n\u001b[32m   1534\u001b[39m     tr_minor_locs = transform.transform(minor_locs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/programming-projects/realtime-nn/.venv/lib/python3.12/site-packages/matplotlib/ticker.py:2230\u001b[39m, in \u001b[36mMaxNLocator.__call__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2228\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   2229\u001b[39m     vmin, vmax = \u001b[38;5;28mself\u001b[39m.axis.get_view_interval()\n\u001b[32m-> \u001b[39m\u001b[32m2230\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtick_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvmax\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/programming-projects/realtime-nn/.venv/lib/python3.12/site-packages/matplotlib/ticker.py:2238\u001b[39m, in \u001b[36mMaxNLocator.tick_values\u001b[39m\u001b[34m(self, vmin, vmax)\u001b[39m\n\u001b[32m   2235\u001b[39m     vmin = -vmax\n\u001b[32m   2236\u001b[39m vmin, vmax = mtransforms.nonsingular(\n\u001b[32m   2237\u001b[39m     vmin, vmax, expander=\u001b[32m1e-13\u001b[39m, tiny=\u001b[32m1e-14\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2238\u001b[39m locs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raw_ticks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvmax\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2240\u001b[39m prune = \u001b[38;5;28mself\u001b[39m._prune\n\u001b[32m   2241\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prune == \u001b[33m'\u001b[39m\u001b[33mlower\u001b[39m\u001b[33m'\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/programming-projects/realtime-nn/.venv/lib/python3.12/site-packages/matplotlib/ticker.py:2168\u001b[39m, in \u001b[36mMaxNLocator._raw_ticks\u001b[39m\u001b[34m(self, vmin, vmax)\u001b[39m\n\u001b[32m   2166\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._nbins == \u001b[33m'\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m   2167\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2168\u001b[39m         nbins = np.clip(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_tick_space\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   2169\u001b[39m                         \u001b[38;5;28mmax\u001b[39m(\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m._min_n_ticks - \u001b[32m1\u001b[39m), \u001b[32m9\u001b[39m)\n\u001b[32m   2170\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2171\u001b[39m         nbins = \u001b[32m9\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/programming-projects/realtime-nn/.venv/lib/python3.12/site-packages/matplotlib/axis.py:2811\u001b[39m, in \u001b[36mYAxis.get_tick_space\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2810\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_tick_space\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m2811\u001b[39m     ends = \u001b[43mmtransforms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mBbox\u001b[49m\u001b[43m.\u001b[49m\u001b[43munit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransformed\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2812\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maxes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransAxes\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdpi_scale_trans\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2813\u001b[39m     length = ends.height * \u001b[32m72\u001b[39m\n\u001b[32m   2814\u001b[39m     \u001b[38;5;66;03m# Having a spacing of at least 2 just looks good.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/programming-projects/realtime-nn/.venv/lib/python3.12/site-packages/matplotlib/transforms.py:466\u001b[39m, in \u001b[36mBboxBase.transformed\u001b[39m\u001b[34m(self, transform)\u001b[39m\n\u001b[32m    462\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    463\u001b[39m \u001b[33;03mConstruct a `Bbox` by statically transforming this one by *transform*.\u001b[39;00m\n\u001b[32m    464\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    465\u001b[39m pts = \u001b[38;5;28mself\u001b[39m.get_points()\n\u001b[32m--> \u001b[39m\u001b[32m466\u001b[39m ll, ul, lr = \u001b[43mtransform\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mpts\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mpts\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpts\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mpts\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpts\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Bbox([ll, [lr[\u001b[32m0\u001b[39m], ul[\u001b[32m1\u001b[39m]]])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/programming-projects/realtime-nn/.venv/lib/python3.12/site-packages/matplotlib/transforms.py:1496\u001b[39m, in \u001b[36mTransform.transform\u001b[39m\u001b[34m(self, values)\u001b[39m\n\u001b[32m   1493\u001b[39m values = values.reshape((-\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.input_dims))\n\u001b[32m   1495\u001b[39m \u001b[38;5;66;03m# Transform the values\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1496\u001b[39m res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform_affine\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform_non_affine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1498\u001b[39m \u001b[38;5;66;03m# Convert the result back to the shape of the input values.\u001b[39;00m\n\u001b[32m   1499\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ndim == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/programming-projects/realtime-nn/.venv/lib/python3.12/site-packages/matplotlib/transforms.py:2411\u001b[39m, in \u001b[36mCompositeGenericTransform.transform_affine\u001b[39m\u001b[34m(self, values)\u001b[39m\n\u001b[32m   2409\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtransform_affine\u001b[39m(\u001b[38;5;28mself\u001b[39m, values):\n\u001b[32m   2410\u001b[39m     \u001b[38;5;66;03m# docstring inherited\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2411\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_affine\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.transform(values)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/programming-projects/realtime-nn/.venv/lib/python3.12/site-packages/matplotlib/transforms.py:2437\u001b[39m, in \u001b[36mCompositeGenericTransform.get_affine\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2435\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._b.get_affine()\n\u001b[32m   2436\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2437\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Affine2D(\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_b\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_affine\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2438\u001b[39m \u001b[43m                           \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_a\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_affine\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# theta = [0.1, 1, 2]\n",
    "\n",
    "class DE_Family(nn.Module):\n",
    "    def __init__(self, NP, CR, F):\n",
    "        super(DE_Family, self).__init__()\n",
    "        lin1s = nn.init.kaiming_uniform_(torch.empty((NP, 8, 4), requires_grad=False).to(device, non_blocking=True))\n",
    "        lin2s = nn.init.kaiming_uniform_(torch.empty((NP, 12, 8), requires_grad=False).to(device, non_blocking=True))\n",
    "        lin3s = nn.init.kaiming_uniform_(torch.empty((NP, 8, 12), requires_grad=False).to(device, non_blocking=True))\n",
    "        lin4s = nn.init.kaiming_uniform_(torch.empty((NP, 4, 8), requires_grad=False).to(device, non_blocking=True))\n",
    "        lin5s = nn.init.kaiming_uniform_(torch.empty((NP, 1, 4), requires_grad=False).to(device, non_blocking=True))\n",
    "        self.layers = [lin1s, lin2s, lin3s, lin4s, lin5s]\n",
    "        bias1 = nn.init.kaiming_uniform_(torch.empty((NP, 8, 1), requires_grad=False).to(device, non_blocking=True))\n",
    "        bias2 = nn.init.kaiming_uniform_(torch.empty((NP, 12, 1), requires_grad=False).to(device, non_blocking=True))\n",
    "        bias3 = nn.init.kaiming_uniform_(torch.empty((NP, 8, 1), requires_grad=False).to(device, non_blocking=True))\n",
    "        bias4 = nn.init.kaiming_uniform_(torch.empty((NP, 4, 1), requires_grad=False).to(device, non_blocking=True))\n",
    "        bias5 = nn.init.kaiming_uniform_(torch.empty((NP, 1, 1), requires_grad=False).to(device, non_blocking=True))\n",
    "        self.biases = [bias1, bias2, bias3, bias4, bias5]\n",
    "        \n",
    "        max_size = 0\n",
    "        for layer in self.layers:\n",
    "            max_size = max(max_size, layer.numel())\n",
    "        for bias in self.biases:\n",
    "            max_size = max(max_size, bias.numel())\n",
    "        diff_evo.pcg_init(max_size)\n",
    "        self.max_size = max_size\n",
    "        \n",
    "        self.NP = NP\n",
    "        self.CR = CR\n",
    "        self.F = F\n",
    "        self.min_f = torch.tensor(float('inf')).to(device)\n",
    "        self.best_model = torch.tensor(0).to(device)\n",
    "        self.fx = None\n",
    "    def forward(self, X):\n",
    "        for i in range(len(self.layers) - 1):\n",
    "            X = torch.relu(torch.matmul(self.layers[i][self.best_model], X) + self.biases[i][self.best_model])\n",
    "        return torch.matmul(self.layers[len(self.layers) - 1][self.best_model], X) + self.biases[len(self.layers) - 1][self.best_model]\n",
    "    def forward_all(self, X, layers, biases):\n",
    "        # This is just bmm???\n",
    "        for i in range(len(layers) - 1):\n",
    "            X = torch.relu(torch.einsum('lik,lkj->lij', layers[i], X) + biases[i])\n",
    "        X = torch.einsum('lik,lkj->lij', layers[len(layers) - 1], X) + biases[len(layers) - 1]\n",
    "        return X\n",
    "    def step(self, X, Y, L, type='param'): # forward pass with candidate i\n",
    "        if self.fx == None:\n",
    "            self.fx = L(self.forward_all(X, self.layers, self.biases), Y).mean(dim = 2).squeeze(-1)\n",
    "        \n",
    "        #y_layers, y_biases = diff_evo.de_crossover_cuda(self.layers, self.biases, self.NP, self.CR, self.F, self.best_model)\n",
    "        y_layers, y_biases = diff_evo.de_crossover_cuda2(self.layers, self.biases, self.NP, self.CR, self.F, self.best_model)\n",
    "        #print(y_layers[0].shape, y_biases[0].shape)\n",
    "        fy = L(self.forward_all(X, y_layers, y_biases), Y).mean(dim = 2).squeeze(-1)\n",
    "        diff_evo.de_update_cuda(self.NP, self.layers, self.biases, y_layers, y_biases, self.fx, fy, self.min_f, self.best_model)\n",
    "\n",
    "epochs = 10000\n",
    "batch_size = 10000\n",
    "\n",
    "def gaussian_mixture2(x, theta):\n",
    "    return gaussian(x, theta[0]) + gaussian(x, theta[1]) + gaussian(x, theta[2])\n",
    "\n",
    "def gaussian_family_mixture(X):\n",
    "    return gaussian_mixture2(X[3], X[0:3])\n",
    "\n",
    "NP = 44\n",
    "CR = 0.9\n",
    "F = 0.8\n",
    "X = torch.rand(4, batch_size).to(device)\n",
    "X[3] = X[3] * 5 - 2.5\n",
    "X[0:3] = X[0:3] * 4 - 2\n",
    "\n",
    "print(X.shape)\n",
    "Y = gaussian_family_mixture(X).to(device)\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "X = X.unsqueeze(0).expand(NP, 4, batch_size)\n",
    "Y = Y.unsqueeze(0).expand(NP, 1, batch_size)\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "model = DE_Family(NP, CR, F).to(device) \n",
    "model = torch.compile(model, mode=\"max-autotune\")\n",
    "print('pcg with max size', model.max_size)\n",
    "L = nn.MSELoss(reduction='none')\n",
    "\n",
    "Y_pred = model.forward_all(X, model.layers, model.biases)\n",
    "print('output shape', Y_pred.shape)\n",
    "\n",
    "my_thetas = [torch.tensor([-1.0, 1.0, 2.0]).to(device), torch.tensor([-1.0, -0.7, 0.0]).to(device), torch.tensor([0.0, 0.8, 1.0]).to(device)]\n",
    "test_Xs = [torch.empty(4, batch_size, device=device) for _ in range(len(my_thetas))]\n",
    "for i in range(len(my_thetas)):\n",
    "    test_Xs[i][0:3, :] = my_thetas[i].unsqueeze(1).expand(-1, batch_size)\n",
    "\n",
    "for e in range(epochs):\n",
    "    model.step(X, Y, L, 'block')\n",
    "    if e % 100 == 0 or e == epochs - 1:\n",
    "        with torch.no_grad():\n",
    "            clear_output(wait=True)\n",
    "            fig, axes = plt.subplots(1, len(my_thetas), figsize=(20, 5))\n",
    "            fig.suptitle(f'loss {model.min_f.item():.4f} epoch {e}')\n",
    "            \n",
    "            for i in range(len(my_thetas)):\n",
    "                ax = axes[i]\n",
    "                \n",
    "                test_Xs[i][3, :] = torch.linspace(-3, 3, batch_size, device=device)\n",
    "                test_Y = gaussian_family_mixture(test_Xs[i]) \n",
    "                model_Y = model(test_Xs[i]).cpu()\n",
    "                \n",
    "                ax.plot(test_Xs[i][3].cpu().numpy(), test_Y.cpu().numpy(), label='')\n",
    "                ax.plot(test_Xs[i][3].cpu().numpy(), model_Y[0].numpy(), label='', color='red', linestyle='dotted')\n",
    "                \n",
    "                ax.set_title(f'gaussian mixture: {my_thetas[i].cpu().numpy()}')\n",
    "                ax.set_xlabel('X')\n",
    "                ax.set_ylim(-1, 3)\n",
    "                ax.grid(True)\n",
    "            axes[0].set_ylabel('Y')\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_evo.pcg_destroy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
